rm(list=ls())

install.packages("foreign")
install.packages("Hmisc")
install.packages("ROCR")
library(foreign)
library(Hmisc)
library(ROCR)
dt1<-sasxport.get("C:/Users/asus/Desktop/data1/DPQ_I.XPT")
dt2<-sasxport.get("C:/Users/asus/Desktop/data1/DR1TOT_I.XPT")
dt3<-sasxport.get("C:/Users/asus/Desktop/data1/DR2TOT_I.XPT")
dt4<-sasxport.get("C:/Users/asus/Desktop/data1/DRXFCD_I.XPT")
dt5<-sasxport.get("C:/Users/asus/Desktop/data1/DR1IFF_I.XPT")
dt6<-sasxport.get("C:/Users/asus/Desktop/data1/DR2IFF_I.XPT")
#write.csv(dt1,file="C:/Users/DTQ/Desktop/20190722/DPQ_I.csv")

a<-c()
for(i in 1:dim(dt1)[1]){
  if(all(is.na(dt1[i,2:11]))){
    a[i]<-F
  }else{
    a[i]<-T
  }
}
dt1<-dt1[a,]

dt1$y<-NA
for(i in 1:dim(dt1)[1]){
  if(all(na.omit(as.numeric(dt1[i,c(2:11)]))==rep(0,length(na.omit(as.numeric(dt1[i,c(2:11)])))))){
    dt1$y[i]<-0
  }else{
    dt1$y[i]<-1
  }
  print(i)
}

inter_name<-intersect(colnames(dt2),colnames(dt3))
dt3<-dt3[,!grepl("wtdrd1|wtdr2d|drabf|drdint",colnames(dt3))]

a<-c()
for(i in 1:dim(dt2)[2]){
  if(length(na.omit(dt2[,i]))/dim(dt2)[1]<0.8){
     print(colnames(dt2)[i])
     a[i]<-F
  }else{
    a[i]<-T
  }
}
dt2<-dt2[,a]

a<-c()
for(i in 1:dim(dt3)[2]){
  if(length(na.omit(dt3[,i]))/dim(dt3)[1]<0.7){
    print(colnames(dt3)[i])
    a[i]<-F
  }else{
    a[i]<-T
  }
}
dt3<-dt3[,a]

dt5<-dt5[,-c(2:18)]
dt6<-dt6[,-c(2:18)]
dt5$seqn<-as.factor(dt5$seqn)
dt6$seqn<-as.factor(dt6$seqn)
dt5<-aggregate(.~seqn,data=dt5,sd)
dt6<-aggregate(.~seqn,data=dt5,sd)

dt<-merge(dt1,dt2,by="seqn",all.x = T)
dt<-merge(dt,dt3,by="seqn",all.x = T)
dt<-merge(dt,dt5,by="seqn",all.x = T)
dt<-merge(dt,dt6,by="seqn",all.x = T)
dt<-dt[,-c(1:11)]
a<-c()
for(i in 1:dim(dt)[2]){
  if(length(na.omit(dt[,i]))/dim(dt)[1]<0.7){
    print(colnames(dt)[i])
    a[i]<-F
  }else{
    a[i]<-T
  }
}
dt<-dt[,a]
save(dt,file="C:/Users/asus/Desktop/data1/dt.rdata")

构造logistics模型
set.seed(2019)
index<-sample(1:dim(dt)[1],0.7*dim(dt)[1])
training_data<-dt[index,]
testing_data<-dt[-index,]

glm_model<-glm(y~.,family = binomial(link = logit), data = training_data )
summary(glm_model)

pre<-predict(glm_model,newdata=testing_data,type="response")
testing_data$pro<-pre
pred<-prediction(pre,testing_data$y)
perf<-performance(pred,'auc')
perf@y.values

######### 构建随机森林 #############

install.packages("pROC")
install.packages("randomForest")
library(pROC)
library(randomForest)

dt<-na.omit(dt)
dt$y<-as.factor(dt$y)
set.seed(2019)
index<-sample(1:dim(dt)[1],0.7*dim(dt)[1])
training_data<-dt[index,]
testing_data<-dt[-index,]
#训练集构建测试集
Boston.rf<-randomForest(y ~ ., 
                        data = training_data,
                        ntree =500,
                        mtry=ceiling(sqrt(dim(training_data)[2])),
                        importance=TRUE ,
                        proximity=TRUE)
plot(Boston.rf)
Boston.rf<-randomForest(y ~ ., 
                        data = training_data,
                        ntree =200,
                        mtry=ceiling(sqrt(dim(training_data)[2])),
                        importance=TRUE ,
                        proximity=TRUE)

Boston.rf

round(importance(Boston.rf), 2) 
varImpPlot(Boston.rf) 

pre_ran <- predict(Boston.rf,newdata=testing_data,type = "prob")
pre_ran<-pre_ran[,2] 
obs_p_ran <- data.frame(prob=pre_ran,obs=testing_data$y)
pred<-prediction(pre_ran,testing_data$y)
perf<-performance(pred,'auc')
perf@y.values

pre <- predict(Boston.rf,newdata=testing_data)
testing_data$y<-as.factor(testing_data$y)
table(testing_data$y,pre,dnn=c("真实值","预测值"))


####################### 集成学习 ###############
rm(list=ls())
load("C:/Users/asus/Desktop/data1/dt.rdata")
dt<-na.omit(dt)
dt$y<-as.factor(dt$y)


############ SVM #################
install.packages("e1071")
library(e1071)
model_svm<-svm(y~., data = dt,type = 'C',kernel = 'radial' )
dt<-dt[,!grepl("dr1drstz|drabf|drdint|dr2drstz",colnames(dt))]
model_svm<-svm(y~., data = dt,type = 'C',kernel = 'radial' )
pre_svm <- predict(model_svm,newdata = dt)

########### RF ####################
model_rf<-randomForest(y ~ ., 
                        data = dt,
                        ntree =500,
                        mtry=ceiling(sqrt(dim(dt)[2])),
                        importance=TRUE ,
                        proximity=TRUE)
plot(model_rf)
model_rf<-randomForest(y ~ ., 
                       data = dt,
                       ntree =200,
                       mtry=ceiling(sqrt(dim(dt)[2])),
                       importance=TRUE ,
                       proximity=TRUE)
pre_rf <- predict(model_rf,newdata = dt)
############ 神经网络 ############
install.packages("nnet")
library(nnet)
set.seed(2019)
model_nn <- nnet(formula = y~., data = dt,size = 3)
pre_nn <- predict(model_nn,newdata = dt)
table(pre_nn)
#pre_nn<-ifelse(pre_nn>0.5,1,0)
#pre_nn<-as.factor(pre_nn)
########## logistic #############

inter_data<-data.frame(y=dt$y,pre_nn=pre_nn,pre_rf=pre_rf,pre_svm=pre_svm)
set.seed(2019)
index<-sample(1:dim(dt)[1],0.7*dim(dt)[1])
training_data<-inter_data[index,]
testing_data<-inter_data[-index,]
glm_model<-glm(y~.,family = binomial(link = logit), data = training_data,control=list(maxit=100) )
summary(glm_model)
pre<-predict(glm_model,newdata=testing_data,type="response")
pre<-as.numeric(pre)
pre<-ifelse(pre>0.5,1,0)
table(pre,testing_data$y)
